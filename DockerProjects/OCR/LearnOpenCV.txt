Tesseract--> First try

#Link Tensorflow Implementation--> https://github.com/argman/EAST

1- Download the East Model

2- Load the Model into memory

3- Prepare the input image

4- Forward pass the blob through the network

5- Process the output

2
cv2.dnn.readNet() function for loading the network into memory. It automatically
detects configuration and framework based on file name specified.

3--->
Prepare the input image
We need to create a 4-D input blob for feeding the image to the network. This is 
done using the blobFromImage function.

blob = cv.dnn.blobFromImage(frame,1.0,(inpwidth, inpHeight ),(123.68,168.78,103.94)
,True, False)

Arguments Used
1- Image itself
2- The scaling of each pixel value. In this case is not required. Thus we keep
it as 1.
3- The default input to the network is 320x320. So, we need to specify while creating
the blob. You can experiment with any other input dimension also.
4- We also specify the mean that should be subtracted from each image since this
was used while training the model.



6- The last argument is whether we want to crop the image and take the center 
crop. Was specified false in that case.


4--->
Forward Pass
Now that we have prepare the input, we will pass it through the network. There
are two outputs of the network.
1- One specifies the geometry of the Text-box.(feature_fusion/concat_3)
2- The other specifies the confidences score of the detected box(feature_fusion/
Conv_7/Sigmoid).

Python------------->
outputLayers = []
outputLayers.append("feature_fusion/Conv_7/Sigmoid")
outputLayers.append("feature fusion/concat 3")

We get the output by passing the input image through the network. As discussed
earlier, the output consists of two parts:
scores and geometry.

net.setInput(blob)
output = net.forward(outputLayers)

scores = output[0]
geometry = output[1]


---> 5
Process the output 
We will use the outputs from both layers (geometry and scores) and decode the
positions of the text boxes along with their orientation. We might get many 
candidates for a text box. Thus,we need to filter out the best looking text-boxes
from the lot. This is done using Non_Maximum Suppression.

Non_Maximum Suppression

We use OpenCv function NMSBoxes(c++) or NMSBoxesRotated(Python) for filtering out
the false positives and get the final predictions.

Python---
indices = cv.dnn.NMSBoxesRotated(boxes, confidences, confThreshold, nmsThreshold)




